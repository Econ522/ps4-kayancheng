{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9803c92c-fec5-42b0-95dc-04f4147b16c2",
   "metadata": {},
   "source": [
    "# Problem Set 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff25f34-87db-4e82-991f-285541111b56",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa8c39-0c90-4db3-ab56-62c754be4930",
   "metadata": {},
   "source": [
    "In this exercise, we numerically study the behaviors of the wild and the pairs bootstrap by considering the following model:\n",
    "\\begin{align}\\label{Q4}\\tag{1}\n",
    "Y_i=Z_{1i} + Z_{2i} + Z_{3i} + \\varrho_0 Z_{1i} Z_{2i} + (1+\\lambda_0 Z_{1i})\\epsilon_i~,\n",
    "\\end{align}\n",
    "for $i=1,\\ldots, n$. The sample $\\{Y_i,Z_{1i},Z_{2i},Z_{3i}\\}_{i=1}^n$ is generated as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208f85b-cec8-4490-96dc-baea914e0c34",
   "metadata": {},
   "source": [
    "(1) Generate $V_i,Z_{2i}$ and $Z_{3i}$ from the standard normal distribution with equal correlation $0.2$, and then set\n",
    "    \\begin{align}\n",
    "    Z_{1i} = \\frac{\\exp(V_i)-E[\\exp(V_i)]}{\\sqrt{\\mathrm{Var}(\\exp(V_i))}}~,\n",
    "    \\end{align}\n",
    "    where $E[\\exp(V_i)]=\\exp(0.5)$ and $\\sqrt{\\mathrm{Var}(\\exp(V_i))}=2.16$ (approximately).\n",
    "\n",
    "(2) Independently, $\\epsilon_i$ is generated from a mixture of a $N(-1/9,1)$ variable with probability $0.9$ and a $N(1,4)$ variable with probability $0.1$. When coding, you may first draw a sample $\\eta_i$ from a Bernoulli distribution with success probability $0.9$, and then you draw $\\epsilon_i$ from $N(-1/9,1)$ if $\\eta_i=1$ and otherwise draw $\\epsilon_i$ from $N(1,4)$. There may be a Python package for implementing this in a compact fashion, but, if not, I would just set $\\epsilon_i=\\eta_i W_{1i} + (1-\\eta_i)W_{2i}$ for $W_{1i}\\sim N(-1/9,1)$ and independently $W_{2i}\\sim N(1,4)$.\n",
    "\n",
    "(3) Generate $Y_i$ according to (1) for each pair $(\\varrho_0,\\lambda_0)$ to be specified.\n",
    "\n",
    "Given $\\{Y_i,Z_{1i},Z_{2i},Z_{3i}\\}_{i=1}^n$, we then consider the following regression:\n",
    "  \\begin{align}\n",
    "  Y_i=\\alpha_0+\\beta_1Z_{1i} + \\beta_2 Z_{2i} + \\beta_3 Z_{3i} + U_i~.\n",
    "  \\end{align}\n",
    "Note that if $\\varrho_0=0$, then $E[U_i|Z_{1i},Z_{2i},Z_{3i}]=0$ (the model is correctly specified), and if $\\varrho_0\\neq 0$, then $E[U_i|Z_{1i},Z_{2i},Z_{3i}]\\neq 0$ so the model is misspecified (but one still has $E[U_i(1,Z_{1i},Z_{2i},Z_{3i})]=0$). The model exhibits conditional heteroskedasticity if $\\lambda_0\\neq 0$. In what follows, set $\\lambda_0=1$ and $n=200$.\n",
    "\n",
    " You should manually generate the bootstrap samples and compute the bootstrap statistics, as described on p.51 of the lecture notes.\n",
    "\n",
    "(a) Let $\\varrho_0=0$. Compute the empirical rejection rates of the two-sided $t$-test for $\\mathrm H_0: \\beta_1=1$ at the significance level $\\alpha=5\\%$, based on the standard normal approximation, the pairs bootstrap and the wild bootstrap using Radamacher weights. Use $5000$ Monte Carlo replications and $200$ bootstrap repetitions. The closer the empirical rejection rates are to $\\alpha$ (the nominal rate), the better the test performs. See the pdf of the problem set for a sketch of the coding structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0fe25dd-29fd-42bf-b598-a9f799580a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sympy.stats import Rademacher, sample\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Settings in question\n",
    "sample_size = 200\n",
    "mu = [0,0,0]\n",
    "var_cov_mat = [[1,0.2,0.2],[0.2,1,0.2],[0.2,0.2,1]]\n",
    "\n",
    "rho_0 = 0\n",
    "ld_0 = 1\n",
    "\n",
    "#Data generating process\n",
    "def dgp(sample_size, mu, var_cov_mat, rho_0, ld_0):\n",
    "    #For v, z2, z3\n",
    "    v, z2, z3 = np.random.multivariate_normal(mu, var_cov_mat, sample_size).T\n",
    "    \n",
    "    #For z1\n",
    "    E_expv = np.exp(0.5)\n",
    "    sd_expv = 2.16\n",
    "    z1 = (np.exp(v) - E_expv)/sd_expv\n",
    "\n",
    "    #Step 2\n",
    "    eta = np.random.binomial(n = 1, p = 0.9, size = sample_size)\n",
    "    w1 = np.random.normal(-1/9, 1, sample_size)\n",
    "    w2 = np.random.normal(1, 2, sample_size)\n",
    "    epsilon = eta*w1 + (1 - eta)*w2\n",
    "\n",
    "    #step 3 \n",
    "    y = z1 + z2 + z3 + rho_0*z1*z2 + (1+ld_0*z1)*epsilon\n",
    "    return y, z1, z2, z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79540933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings in question\n",
    "R = 5000                  #Number of Monte Carlo replications\n",
    "b_sample_size = 200       #Sample size in bootstrapping\n",
    "B = 200                   #Bootstrap reptitions\n",
    "b_0 = 1                   #Null hypothesis value of beta1\n",
    "\n",
    "#Start to compute the empirical rejection rule\n",
    "def emp_rej_rule(sample_size, mu, var_cov_mat, rho_0, ld_0, R, b_sample_size, B, b_0):\n",
    "    \n",
    "    RejN_list = []\n",
    "    RejP_list = []\n",
    "    RejW_list = []\n",
    "    \n",
    "    for rep in tqdm(range(0,R)):\n",
    "        \n",
    "        #Generate a sample\n",
    "        s = dgp(sample_size, mu, var_cov_mat, rho_0, ld_0)\n",
    "        y = s[0]\n",
    "        x_woc = np.transpose(s[1:])\n",
    "\n",
    "        #Compute t-stat t_n after doing OLS regression\n",
    "        x = sm.add_constant(x_woc)\n",
    "        model = sm.OLS(y, x)\n",
    "        model = model.fit(cov_type='HC1')\n",
    "        t_n = (model.params[1] - b_0)/(model.bse[1]) #just get it for beta1\n",
    "        t_n = np.abs(t_n)\n",
    "        \n",
    "        #Constrained least square for wild bootstrap\n",
    "        x_cls_woc = np.transpose(s[2:])\n",
    "        x_cls = sm.add_constant(x_cls_woc)\n",
    "        y_cls = y-(s[1]*b_0)\n",
    "        model_cls = sm.OLS(y_cls, x_cls)\n",
    "        model_cls = model_cls.fit(cov_type='HC1')\n",
    "        cls_resid = model_cls.resid\n",
    "\n",
    "        #Get ready for bootstrap\n",
    "        t_n_P_list = []\n",
    "        t_n_w_list = []\n",
    "        \n",
    "        #Bootrapping starts\n",
    "        for b in range(0, B):\n",
    "            \n",
    "            #pair bootstrap\n",
    "            rd = np.random.choice(sample_size, b_sample_size)  #draw (with replacement) `b_sample_size` number from range(0, sample_size)\n",
    "            BootP_y = y[rd]\n",
    "            BootP_x_woc = x_woc[rd,]\n",
    "            BootP_x = sm.add_constant(BootP_x_woc)\n",
    "            model_P = sm.OLS(BootP_y, BootP_x)\n",
    "            model_P = model_P.fit(cov_type='HC1')\n",
    "            t_n_P = (model_P.params[1] - model.params[1])/(model_P.bse[1]) #just get it for beta1\n",
    "            t_n_P_list.append(np.abs(t_n_P))\n",
    "            \n",
    "            #wild bootstrap #Redimicher\n",
    "            X = Rademacher('X')\n",
    "            r = sample(X, size = b_sample_size)\n",
    "            Bootw_u = cls_resid*r\n",
    "            Bootw_y = model_cls.predict() + s[1]*b_0  + Bootw_u\n",
    "            model_w = sm.OLS(Bootw_y, x)\n",
    "            model_w = model_w.fit(cov_type='HC1')\n",
    "            t_n_w = (model_w.params[1] - b_0)/(model_w.bse[1]) #just get it for beta1, cls estimator of beta1 = 1\n",
    "            t_n_w_list.append(np.abs(t_n_w))\n",
    "\n",
    "        CriticalP = np.percentile(t_n_P_list, 95)\n",
    "        CriticalW = np.percentile(t_n_w_list, 95)\n",
    "\n",
    "        RejN_list.append(1*(t_n>1.96))\n",
    "        RejP_list.append(1*(t_n>CriticalP))\n",
    "        RejW_list.append(1*(t_n>CriticalW))\n",
    "\n",
    "    RejN = np.mean(RejN_list)\n",
    "    RejP = np.mean(RejP_list)\n",
    "    RejW = np.mean(RejW_list)\n",
    "    \n",
    "    print(\"Empirical Rejection rates based on:\")\n",
    "    print(\"1. The standard normal approximation: \" + str(RejN))\n",
    "    print(\"2. The pair bootstrap: \" + str(RejP))\n",
    "    print(\"3. The wild bootstrap using Radamacher weight: \" + str(RejW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5cec36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [41:04<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Rejection rates based on:\n",
      "1. The standard normal approximation: 0.1666\n",
      "2. The pair bootstrap: 0.0712\n",
      "3. The wild bootstrap using Radamacher weight: 0.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Run the bootstrap\n",
    "emp_rej_rule(sample_size, mu, var_cov_mat, rho_0, ld_0, R, b_sample_size, B, b_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440b433-cd1a-4ab3-b13b-e06acaffb567",
   "metadata": {},
   "source": [
    "(b) Repeat part (a) by setting $\\varrho_0\\in\\{-0.5,0.5\\}$ (so the model is misspecified), but now consider the two-sided $t$ test for $\\mathrm H_0: \\beta_1=1+\\varrho_0 b$ for $b=0.41$ (note that $1+\\varrho_0 b$ is the slope parameter for $Z_{1i}$ in the best linear prediction of $Y_i$ given $1,Z_{1i},Z_{2i}$, and $Z_{3i}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ae46ec-5764-495e-8e2b-98cccfa4272e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [40:41<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Rejection rates based on:\n",
      "1. The standard normal approximation: 0.1714\n",
      "2. The pair bootstrap: 0.0616\n",
      "3. The wild bootstrap using Radamacher weight: 0.0538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#For rho_0 = -0.5\n",
    "\n",
    "#Update rho_0 and b_0\n",
    "rho_0 = -0.5\n",
    "b_0 = 1+rho_0*0.41\n",
    "\n",
    "#Run the bootstrap\n",
    "emp_rej_rule(sample_size, mu, var_cov_mat, rho_0, ld_0, R, b_sample_size, B, b_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e949b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [40:44<00:00,  2.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Rejection rates based on:\n",
      "1. The standard normal approximation: 0.1806\n",
      "2. The pair bootstrap: 0.0746\n",
      "3. The wild bootstrap using Radamacher weight: 0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#For rho_0 = 0.5\n",
    "\n",
    "#Update rho_0 and b_0\n",
    "rho_0 = 0.5\n",
    "b_0 = 1+rho_0*0.41 \n",
    "\n",
    "#Run the bootstrap\n",
    "emp_rej_rule(sample_size, mu, var_cov_mat, rho_0, ld_0, R, b_sample_size, B, b_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac1237-1d7e-4d39-9855-fd6e7283bb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
